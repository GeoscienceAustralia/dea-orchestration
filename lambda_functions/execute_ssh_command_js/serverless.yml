# Welcome to Serverless!
#
# This file is the main config file for your service.
#
# For full config options, check the docs:
#    docs.serverless.com
#
# Happy Coding!
service: execute-on

# You can pin your service to only deploy with a specific Serverless version
# Check out our docs for more details
# frameworkVersion: "=X.X.X"

# plugins:
plugins:
  # install serverless pseudo parameters using the following:
  #   1) $ npm install serverless-pseudo-parameters --save-dev
  - serverless-pseudo-parameters

custom:
  Stage: ${opt:stage, self:provider.stage}
  profiles:
    dev: devProfile
    prod: prodProfile
  CustEnv:
    s3Bucket:
      prod: "dea-lambda"
      dev: "dea-lambdas-dev"

provider:
  name: aws
  runtime: nodejs6.10
  timeout: 300 # 5 minutes. Default is 6 seconds
  profile: ${self:custom.profiles.${self:custom.Stage}}
  environment:
    hostkey: 'orchestrator.raijin.users.default.host'
    userkey: 'orchestrator.raijin.users.default.user'
    pkey: 'orchestrator.raijin.users.default.pkey'
    DEA_MODULE: dea/20181015
    PROJECT: v10
    QUEUE: normal
  region: ap-southeast-2
  deploymentBucket: ${self:custom.CustEnv.s3Bucket.${self:custom.Stage}}
  stackTags:
    repo: dea-orchestration
    author: nci.monitor@dea.ga.gov.au
    purpose: nci-automation
# you can add statements to the Lambda function's IAM Role here
  iamRoleStatements:
    - Effect: 'Allow'
      Action:
        - 'ssm:GetParameters'
        - 'ssm:DescribeParameters'
      Resource:
        - "arn:aws:ssm:#{AWS::Region}:#{AWS::AccountId}:parameter/orchestrator.*"
        - "arn:aws:ssm:#{AWS::Region}:#{AWS::AccountId}:parameter/pipeline.*"
    - Effect: 'Allow'
      Action: 'kms:Decrypt'
      Resource:
        - "arn:aws:kms:#{AWS::Region}:#{AWS::AccountId}:key/*"

functions:
  git_pull_prod:
    handler: handler.execute_ssh_command
    environment:
      hostkey: 'orchestrator.raijin.users.git_pull.host'
      userkey: 'orchestrator.raijin.users.git_pull.user'
      pkey: 'orchestrator.raijin.users.git_pull.pkey'
    events:
      - schedule:
          rate: cron(00 10 ? * FRI,SAT,SUN *) # Run every Friday-Sunday, at 08:00 pm Canberra time
          enabled: true
  execute_sync:
    # trasharchived is set to 'yes' only for the albers products and not for the scenes
    handler: handler.execute_ssh_command
    description: Execute dea-sync tool to sync datasets from the specified path
    environment:
      cmd: 'execute_sync --dea-module ${self:provider.environment.DEA_MODULE}
                         --queue ${self:provider.environment.QUEUE}
                         --project ${self:provider.environment.PROJECT}
                         --stage ${self:custom.Stage}
                         --year <%= year %>
                         --path <%= path %>
                         --product <%= product %>
                         --trasharchived <%= trasharchived %>'
    events:
      - schedule:
          rate: cron(10 10 ? * FRI *) # Run every Friday, at 08:10 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: ls8_pq_scene
            path: '/g/data/rs0/scenes/pq-scenes-tmp/ls8/2018/'
            trasharchived: no
      - schedule:
          rate: cron(10 10 ? * FRI *) # Run every Friday, at 08:10 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: ls8_pq_legacy_scene
            path: '/g/data/rs0/scenes/pq-legacy-scenes-tmp/ls8/2018/'
            trasharchived: no
      - schedule:
          rate: cron(10 10 ? * FRI *) # Run every Friday, at 08:10 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: ls8_nbart_scene
            path: '/g/data/rs0/scenes/nbar-scenes-tmp/ls8/2018/??/output/nbart/'
            trasharchived: no
      - schedule:
          rate: cron(10 10 ? * FRI *) # Run every Friday, at 08:10 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: ls8_nbar_scene
            path: '/g/data/rs0/scenes/nbar-scenes-tmp/ls8/2018/??/output/nbar/'
            trasharchived: no
      - schedule:
          rate: cron(10 10 ? * FRI *) # Run every Friday, at 08:10 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: ls7_pq_scene
            path: '/g/data/rs0/scenes/pq-scenes-tmp/ls7/2018/'
            trasharchived: no
      - schedule:
          rate: cron(10 10 ? * FRI *) # Run every Friday, at 08:10 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: ls7_pq_legacy_scene
            path: '/g/data/rs0/scenes/pq-legacy-scenes-tmp/ls7/2018/'
            trasharchived: no
      - schedule:
          rate: cron(10 10 ? * FRI *) # Run every Friday, at 08:10 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: ls7_nbart_scene
            path: '/g/data/rs0/scenes/nbar-scenes-tmp/ls7/2018/??/output/nbart/'
            trasharchived: no
      - schedule:
          rate: cron(10 10 ? * FRI *) # Run every Friday, at 08:10 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: ls7_nbar_scene
            path: '/g/data/rs0/scenes/nbar-scenes-tmp/ls7/2018/??/output/nbar/'
            trasharchived: no
  execute_ingest:
    handler: handler.execute_ssh_command
    description: Execute dea-submit-ingest qsub tool to ingest datasets to the database
    environment:
      cmd: 'execute_ingest --dea-module ${self:provider.environment.DEA_MODULE}
                           --queue ${self:provider.environment.QUEUE}
                           --project ${self:provider.environment.PROJECT}
                           --stage ${self:custom.Stage}
                           --year <%= year %>
                           --product <%= product %>'
    events:
      - schedule:
          rate: cron(15 10 ? * SAT *) # Run every Saturday, at 08:15 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: ls8_nbart_albers
      - schedule:
          rate: cron(15 10 ? * SAT *) # Run every Saturday, at 08:15 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: ls8_nbar_albers
      - schedule:
          rate: cron(15 10 ? * SAT *) # Run every Saturday, at 08:15 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: ls8_pq_albers
      - schedule:
          rate: cron(15 10 ? * SAT *) # Run every Saturday, at 08:15 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: ls7_nbart_albers
      - schedule:
          rate: cron(15 10 ? * SAT *) # Run every Saturday, at 08:15 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: ls7_nbar_albers
      - schedule:
          rate: cron(15 10 ? * SAT *) # Run every Saturday, at 08:15 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: ls7_pq_albers
  execute_fractional_cover:
    handler: handler.execute_ssh_command
    description: Execute datacube-fc submit tool to generate fc and ingest them to the database
    environment:
      cmd: 'execute_fractional_cover --dea-module ${self:provider.environment.DEA_MODULE}
                                     --queue ${self:provider.environment.QUEUE}
                                     --project ${self:provider.environment.PROJECT}
                                     --stage ${self:custom.Stage}
                                     --year <%= year %>
                                     --product <%= product %>
                                     --tag <%= tag %>'
    events:
      - schedule:
          rate: cron(15 10 ? * SUN *) # Run every Sunday, at 08:15 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: ls8_fc_albers
            tag: 'ls8_fc2018'
      - schedule:
          rate: cron(15 10 ? * SUN *) # Run every Sunday, at 08:15 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: ls7_fc_albers
            tag: 'ls7_fc2018'
  execute_wofs:
    handler: handler.execute_ssh_command
    description: Execute datacube-wofs submit tool to generate wofs and ingest them to the database
    environment:
      cmd: 'execute_wofs --dea-module ${self:provider.environment.DEA_MODULE}
                         --queue ${self:provider.environment.QUEUE}
                         --project ${self:provider.environment.PROJECT}
                         --stage ${self:custom.Stage}
                         --year <%= year %>
                         --product <%= product %>
                         --tag <%= tag %>'
    events:
      - schedule:
          rate: cron(20 10 ? * SUN *) # Run every Sunday, at 08:20 pm Canberra time
          enabled: true
          input:
            year: 2018
            product: wofs_albers
            tag: '2018'
  execute_coherence:
    # execute_coherence shall not be used on nbar/nbart/pq albers products
    handler: handler.execute_ssh_command
    description: Execute dea-coherence tool to check the database inconsistencies (duplicates, siblings, locationless)
    environment:
      cmd: 'execute_coherence --dea-module ${self:provider.environment.DEA_MODULE}
                              --queue ${self:provider.environment.QUEUE}
                              --project ${self:provider.environment.PROJECT}
                              --timerange <%= timerange %>'
    events:
      - schedule:
          rate: cron(00 09 ? * * *) # Run every day, at 07:00 pm Canberra time
          enabled: false
          input:
            timerange: "'\''time in 2018'\''"
  execute_notify_on_error_ds:
    handler: handler.email_notification
    description: Upload csv file to S3 and send an email, if coherence tool detects bad datasets in the database
    environment:
      cmd: 'execute_notify_on_error_ds --dea-module ${self:provider.environment.DEA_MODULE}'
    events:
      - schedule:
          rate: cron(00 10 ? * * *) # Run every day, at 08:00 pm Canberra time
          enabled: false
  execute_clean:
    handler: handler.execute_ssh_command
    description: Execute dea-clean tool to clean the file on the disk
    environment:
      cmd: 'execute_clean --dea-module ${self:provider.environment.DEA_MODULE}
                          --queue ${self:provider.environment.QUEUE}
                          --project ${self:provider.environment.PROJECT}
                          --min-trash-age-hours <%= mintrashage %>
                          --search-string <%= searchstr %>'
    events:
      - schedule:
          rate: cron(00 11 ? * SUN *) # Run every Sunday, at 09:00 pm Canberra time
          enabled: false
          input:
            mintrashage: 10
            searchstr: ls8_nbar_albers
