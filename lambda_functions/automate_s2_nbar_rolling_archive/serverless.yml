service: automate-s2-rolling-archive

plugins:
  - serverless-python-requirements
  - serverless-pseudo-parameters
custom:
  pythonRequirements:
    dockerizePip: non-linux
  Stage: ${opt:stage, self:provider.stage}
  profiles:
    dev: devProfile
    prod: prodProfile
  s3Bucket:
    prod: "dea-public-data"
    dev: "dea-public-data-dev"

package:
  exclude:
    - node_modules/**
    - .idea/**
    - .requirements/**
    - env/**
    - README.md
    - package.json
    - package-lock.json
    - requirements.txt

provider:
  name: aws
  runtime: python3.7
  timeout: 60  # 60 seconds. Default is 6 seconds
  memorySize: 128  # in MB, default is 1024
  region: ap-southeast-2
  stage: dev
  profile: ${self:custom.profiles.${self:custom.Stage}}
  iamRoleStatements:
  - Effect: 'Allow'
    Action:
      - 'ssm:GetParameters'
      - 'ssm:GetParameter'
      - 'ssm:DescribeParameters'
    Resource:
      - "arn:aws:ssm:#{AWS::Region}:#{AWS::AccountId}:parameter/orchestrator.*"
      - "arn:aws:ssm:#{AWS::Region}:#{AWS::AccountId}:parameter/pipeline.*"
  - Effect: 'Allow'
    Action: 'kms:Decrypt'
    Resource:
      - "arn:aws:kms:#{AWS::Region}:#{AWS::AccountId}:key/*"
  - Effect: "Allow"
    Resource: "*"
    Action:
      - "sns:*"

  # Service wide environment variables declaration
  environment:
    SSM_USER_PATH: 'orchestrator.raijin.users.default'
    LEVEL1_DONE_LIST: ['/g/data/v10/work/s2_ard/wagl/batchid-1bafe0dd96/level-1-done.txt',
                       '/g/data/v10/work/s2_ard/wagl/batchid-21e0db8763/level-1-done.txt',
                       '/g/data/v10/work/s2_ard/wagl/batchid-02c261496d/level-1-done.txt']
    AWS_PROFILE: ${self:custom.profiles.${self:custom.Stage}}
    S3_BUCKET: ${self:custom.s3Bucket.${self:custom.Stage}}

functions:
  AutomateRollingS2NbarArchive:
    handler: handler.handler
    description: Upload monthly s3 stats csv file
    events:
      - schedule: cron(30 23 ? * THU *)  # Run every Thursday, at 10:30 am Canberra time
